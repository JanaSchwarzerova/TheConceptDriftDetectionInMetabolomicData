{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras – Classification using DNN with Keras",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u6rAHDude9t"
      },
      "source": [
        "## Deep learning network (using KERAS) – DDM & EDDM\n",
        "\n",
        "#KERAS: \n",
        "Chollet, F., & others. (2015). Keras. GitHub. Retrieved from https://github.com/fchollet/keras\n",
        "\n",
        "#DDM\n",
        "Link to the tool: https://github.com/scikit-multiflow/scikit-multiflow/blob/a7e316d/src/skmultiflow/drift_detection/ddm.py#L6\n",
        "Documentation: https://scikit-multiflow.readthedocs.io/en/stable/api/generated/skmultiflow.drift_detection.DDM.html\n",
        "Paper reference: https://link.springer.com/chapter/10.1007/978-3-540-28645-5_29\n",
        "\n",
        "#EDDM\n",
        "Link to the tool: https://github.com/scikit-multiflow/scikit-multiflow/blob/a7e316d/src/skmultiflow/drift_detection/eddm.py#L6\n",
        "Documentation: https://scikit-multiflow.readthedocs.io/en/stable/api/generated/skmultiflow.drift_detection.EDDM.html#skmultiflow.drift_detection.EDDM\n",
        "Paper reference: https://www.researchgate.net/profile/Albert-Bifet/publication/245999704_Early_Drift_Detection_Method/links/53e582cd0cf21cc29fd06017/Early-Drift-Detection-Method.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhUHK7bfpNRv"
      },
      "source": [
        "!pip install scikit-multiflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWjKWL6vm9F3"
      },
      "source": [
        "# multi-class classification with Keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        " \n",
        "# load dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        " \n",
        "# Loading a dataset\n",
        "\n",
        "#url = '/content/drive/MyDrive/Dataset/Dataset_without0/FinalDataBM_bcp.csv'\n",
        "#url = '/content/drive/MyDrive/Dataset/Dataset_without0/FinalDataGM_bcp.csv'\n",
        "#url = '/content/drive/MyDrive/Dataset/Dataset_without0/FinalDataBM_gender.csv'\n",
        "#url = '/content/drive/MyDrive/Dataset/Dataset_without0/FinalDataGM_gender.csv'\n",
        "#url = '/content/drive/MyDrive/Dataset/Dataset_without0/FinalDataBM_sm.csv'\n",
        "url = '/content/drive/MyDrive/Dataset/Dataset_without0/FinalDataGM_sm.csv'\n",
        " \n",
        "data_frame = pd.read_csv(url, delimiter=';')\n",
        "def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~data_frame.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return data_frame[indices_to_keep].astype(np.float64)\n",
        " \n",
        "data_frame = clean_dataset(data_frame)\n",
        "# Splitting the dataset\n",
        "#X, Y = data_frame.drop(columns=\"bcp\"), data_frame.bcp\n",
        "#X, Y = data_frame.drop(columns=\"gender\"), data_frame.gender\n",
        "X, Y = data_frame.drop(columns=\"smoker\"), data_frame.smoker\n",
        " \n",
        "train_X, test_X, train_Y, test_Y = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42\n",
        ")\n",
        " \n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_Y)\n",
        "encoded_Y = encoder.transform(train_Y)\n",
        " \n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(150, input_dim=1589, activation='relu'))\n",
        "    model.add(Dense(50, activation='softmax'))\n",
        "    model.add(Dense(150, input_dim=1589, activation='relu'))\n",
        "    model.add(Dense(80, activation='softmax'))\n",
        "    model.add(Dense(33, activation='softmax'))\n",
        "    model.add(Dense(4, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        " \n",
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=3000, batch_size=5, verbose=True)\n",
        "train_model = estimator.fit(train_X, train_Y)\n",
        "predicted = estimator.predict(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O28orOkBT5Jz"
      },
      "source": [
        "#DDM\n",
        "from skmultiflow.drift_detection.ddm import DDM\n",
        "ddm = DDM()\n",
        "\n",
        "# Adding stream elements to DDM and verifying if drift occurred\n",
        "\n",
        "for i in range(len(predicted)):\n",
        "    ddm.add_element(predicted[i])\n",
        "    if ddm.detected_warning_zone():\n",
        "        print('Warning zone has been detected in data: ' + str(predicted[i]) + ' - of index: ' + str(i))\n",
        "    if ddm.detected_change():\n",
        "        print('Change detected in data: ' + str(predicted[i]) + ' - at index: ' + str(i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df8p75f8ovFp"
      },
      "source": [
        "#EDDM\n",
        "from skmultiflow.drift_detection.eddm import EDDM\n",
        "eddm = EDDM()\n",
        "\n",
        "# Adding stream elements to EDDM and verifying if drift occurred\n",
        "\n",
        "for i in range(len(predicted)):\n",
        "    eddm.add_element(predicted[i])\n",
        "    if eddm.detected_warning_zone():\n",
        "        print('Warning zone has been detected in data: ' + str(predicted[i]) + ' - of index: ' + str(i))\n",
        "    if eddm.detected_change():\n",
        "        print('Change detected in data: ' + str(predicted[i]) + ' - at index: ' + str(i))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}